"""
LangGraph Agent Implementation
"""
import json
import logging
from typing import Dict, Any, List, Optional, AsyncGenerator
from datetime import datetime

from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage

from ..models.state import AgentState, ToolCall, StreamEvent
from ..tools.registry import tool_registry
from ..config import OPENAI_API_KEY, OPENAI_MODEL, OPENAI_BASE_URL, MAX_ITERATIONS

logger = logging.getLogger(__name__)

# System prompt
SYSTEM_PROMPT = """ä½ æ˜¯ ResearchGO çš„ AI ç ”ç©¶åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·è¿›è¡Œå­¦æœ¯ç ”ç©¶ã€‚

ä½ çš„èƒ½åŠ›ï¼š
1. æœç´¢å­¦æœ¯æ–‡çŒ®ï¼ˆOpenAlex æ•°æ®åº“ï¼ŒåŒ…å«æ•°äº¿ç¯‡è®ºæ–‡ï¼‰
2. ç®¡ç†ç”¨æˆ·çš„è®ºæ–‡åº“ï¼ˆä¸Šä¼ ã€æœç´¢ã€æŸ¥çœ‹ï¼‰
3. è¯­ä¹‰æœç´¢ï¼ˆåŸºäºå†…å®¹çš„æ™ºèƒ½æ£€ç´¢ï¼‰
4. è®ºæ–‡é—®ç­”ï¼ˆåŸºäºè®ºæ–‡å†…å®¹å›ç­”é—®é¢˜ï¼‰
5. è®ºæ–‡åˆ†æï¼ˆç”Ÿæˆåˆ†ææŠ¥å‘Šã€æ€ç»´å¯¼å›¾ï¼‰
6. è®ºæ–‡å¯¹æ¯”ï¼ˆå¯¹æ¯”å¤šç¯‡è®ºæ–‡çš„å¼‚åŒï¼‰

å·¥ä½œåŸåˆ™ï¼š
1. ä¼˜å…ˆç†è§£ç”¨æˆ·æ„å›¾ï¼Œé€‰æ‹©æœ€åˆé€‚çš„å·¥å…·
2. å¦‚æœéœ€è¦å¤šæ­¥æ“ä½œï¼ŒæŒ‰é¡ºåºæ‰§è¡Œ
3. å·¥å…·è¿”å›ç»“æœåï¼Œç”¨è‡ªç„¶è¯­è¨€æ€»ç»“ç»™ç”¨æˆ·
4. å¦‚æœå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ¡ˆæˆ–å‘ŠçŸ¥ç”¨æˆ·
5. å›ç­”è¦ç®€æ´æ¸…æ™°ï¼Œé‡ç‚¹çªå‡º

ä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·ï¼š
{tool_descriptions}

è®°ä½ï¼šä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶åŠ©æ‰‹ï¼Œè¦å¸®åŠ©ç”¨æˆ·é«˜æ•ˆåœ°å®Œæˆç ”ç©¶ä»»åŠ¡ã€‚"""


class ResearchAgent:
    """ResearchGO Agent åŸºäº LangGraph"""
    
    def __init__(self):
        # åˆå§‹åŒ– LLM
        llm_kwargs = {
            "model": OPENAI_MODEL,
            "temperature": 0.7,
            "api_key": OPENAI_API_KEY,
        }
        if OPENAI_BASE_URL:
            llm_kwargs["base_url"] = OPENAI_BASE_URL
        
        self.llm = ChatOpenAI(**llm_kwargs)
        
        # ç»‘å®šå·¥å…·åˆ° LLM
        self.tools = tool_registry.get_openai_functions()
        self.llm_with_tools = self.llm.bind_tools(self.tools)
        
        # æ„å»ºå›¾
        self.graph = self._build_graph()
        self.app = self.graph.compile()
    
    def _build_graph(self) -> StateGraph:
        """æ„å»º LangGraph çŠ¶æ€å›¾"""
        graph = StateGraph(AgentState)
        
        # æ·»åŠ èŠ‚ç‚¹
        graph.add_node("reason", self._reason_node)
        graph.add_node("execute_tools", self._execute_tools_node)
        graph.add_node("respond", self._respond_node)
        
        # è®¾ç½®å…¥å£ç‚¹
        graph.set_entry_point("reason")
        
        # æ·»åŠ æ¡ä»¶è¾¹
        graph.add_conditional_edges(
            "reason",
            self._should_continue,
            {
                "execute_tools": "execute_tools",
                "respond": "respond",
                "end": END
            }
        )
        
        # å·¥å…·æ‰§è¡Œåå›åˆ°æ¨ç†èŠ‚ç‚¹
        graph.add_edge("execute_tools", "reason")
        
        # å“åº”èŠ‚ç‚¹ç»“æŸ
        graph.add_edge("respond", END)
        
        return graph
    
    async def _reason_node(self, state: AgentState) -> Dict[str, Any]:
        """æ¨ç†èŠ‚ç‚¹ï¼šåˆ†æç”¨æˆ·æ„å›¾ï¼Œå†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·"""
        logger.info(f"Reason node - iteration: {state.get('iteration', 0)}")
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [
            SystemMessage(content=SYSTEM_PROMPT.format(
                tool_descriptions=tool_registry.get_tool_descriptions()
            ))
        ]
        
        # æ·»åŠ å†å²æ¶ˆæ¯
        for msg in state.get("messages", []):
            if msg["role"] == "user":
                messages.append(HumanMessage(content=msg["content"]))
            elif msg["role"] == "assistant":
                # æ£€æŸ¥æ˜¯å¦æœ‰ tool_calls
                if msg.get("tool_calls"):
                    # åˆ›å»ºå¸¦æœ‰ tool_calls çš„ AIMessage
                    ai_msg = AIMessage(
                        content=msg.get("content", ""),
                        tool_calls=msg["tool_calls"]
                    )
                    messages.append(ai_msg)
                else:
                    messages.append(AIMessage(content=msg.get("content", "")))
            elif msg["role"] == "tool":
                messages.append(ToolMessage(
                    content=msg["content"],
                    tool_call_id=msg.get("tool_call_id", "")
                ))
        
        # è°ƒç”¨ LLM
        response = await self.llm_with_tools.ainvoke(messages)
        
        # å¤„ç†å“åº”
        tool_calls = []
        thoughts = state.get("thoughts", [])
        
        if response.tool_calls:
            # LLM å†³å®šè°ƒç”¨å·¥å…·
            for tc in response.tool_calls:
                tool_calls.append(ToolCall(
                    id=tc["id"],
                    name=tc["name"],
                    arguments=tc["args"]
                ))
                thoughts.append(f"ğŸ”§ å‡†å¤‡è°ƒç”¨å·¥å…·: {tc['name']}")
            
            return {
                "messages": [{"role": "assistant", "content": response.content or "", "tool_calls": response.tool_calls}],
                "tool_calls": tool_calls,
                "thoughts": thoughts,
                "should_continue": True,
                "iteration": state.get("iteration", 0) + 1
            }
        else:
            # LLM ç›´æ¥å›ç­”
            return {
                "messages": [{"role": "assistant", "content": response.content}],
                "final_answer": response.content,
                "should_continue": False,
                "iteration": state.get("iteration", 0) + 1
            }
    
    async def _execute_tools_node(self, state: AgentState) -> Dict[str, Any]:
        """å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹"""
        logger.info("Execute tools node")
        
        tool_calls = state.get("tool_calls", [])
        thoughts = state.get("thoughts", [])
        new_messages = []
        
        for tc in tool_calls:
            tool = tool_registry.get(tc.name)
            if not tool:
                error_msg = f"å·¥å…· {tc.name} ä¸å­˜åœ¨"
                thoughts.append(f"âŒ {error_msg}")
                new_messages.append({
                    "role": "tool",
                    "content": json.dumps({"error": error_msg}),
                    "tool_call_id": tc.id
                })
                continue
            
            # æ‰§è¡Œå·¥å…·
            thoughts.append(f"âš™ï¸ æ­£åœ¨æ‰§è¡Œ: {tc.name}")
            
            # æ·»åŠ  tokenï¼ˆå¦‚æœçŠ¶æ€ä¸­æœ‰çš„è¯ï¼‰
            kwargs = tc.arguments.copy()
            if state.get("token"):
                kwargs["token"] = state["token"]
            
            result = await tool(**kwargs)
            
            if result.success:
                thoughts.append(f"âœ… {tc.name} æ‰§è¡ŒæˆåŠŸ")
                new_messages.append({
                    "role": "tool",
                    "content": json.dumps(result.data, ensure_ascii=False),
                    "tool_call_id": tc.id
                })
            else:
                thoughts.append(f"âŒ {tc.name} æ‰§è¡Œå¤±è´¥: {result.error}")
                new_messages.append({
                    "role": "tool",
                    "content": json.dumps({"error": result.error}),
                    "tool_call_id": tc.id
                })
            
            # æ›´æ–°å·¥å…·è°ƒç”¨ç»“æœ
            tc.result = result.data if result.success else None
            tc.error = result.error if not result.success else None
            tc.duration_ms = result.duration_ms
        
        return {
            "messages": new_messages,
            "thoughts": thoughts,
            "tool_calls": []  # æ¸…ç©ºå·²æ‰§è¡Œçš„å·¥å…·è°ƒç”¨
        }
    
    async def _respond_node(self, state: AgentState) -> Dict[str, Any]:
        """å“åº”èŠ‚ç‚¹ï¼šç”Ÿæˆæœ€ç»ˆå›ç­”"""
        logger.info("Respond node")
        return {
            "final_answer": state.get("final_answer", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚")
        }
    
    def _should_continue(self, state: AgentState) -> str:
        """å†³å®šä¸‹ä¸€æ­¥èµ°å‘"""
        iteration = state.get("iteration", 0)
        
        # æ£€æŸ¥è¿­ä»£æ¬¡æ•°é™åˆ¶
        if iteration >= MAX_ITERATIONS:
            logger.warning(f"Max iterations ({MAX_ITERATIONS}) reached")
            return "respond"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·éœ€è¦æ‰§è¡Œ
        if state.get("tool_calls"):
            return "execute_tools"
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»§ç»­
        if state.get("should_continue", False):
            return "execute_tools"
        
        # æœ‰æœ€ç»ˆç­”æ¡ˆåˆ™ç»“æŸ
        if state.get("final_answer"):
            return "end"
        
        return "respond"
    
    async def run(
        self,
        user_input: str,
        user_id: Optional[str] = None,
        token: Optional[str] = None,
        conversation_history: Optional[List[dict]] = None
    ) -> Dict[str, Any]:
        """è¿è¡Œ Agentï¼ˆéæµå¼ï¼‰"""
        initial_state = {
            "messages": conversation_history or [],
            "user_input": user_input,
            "user_id": user_id,
            "token": token,
            "tool_calls": [],
            "iteration": 0,
            "should_continue": True,
            "final_answer": None,
            "error": None,
            "thoughts": []
        }
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        initial_state["messages"].append({"role": "user", "content": user_input})
        
        # è¿è¡Œå›¾
        final_state = await self.app.ainvoke(initial_state)
        
        return {
            "answer": final_state.get("final_answer", ""),
            "thoughts": final_state.get("thoughts", []),
            "tool_calls": final_state.get("tool_calls", [])
        }
    
    async def run_stream(
        self,
        user_input: str,
        user_id: Optional[str] = None,
        token: Optional[str] = None,
        conversation_history: Optional[List[dict]] = None
    ) -> AsyncGenerator[StreamEvent, None]:
        """è¿è¡Œ Agentï¼ˆæµå¼ï¼‰"""
        initial_state = {
            "messages": conversation_history or [],
            "user_input": user_input,
            "user_id": user_id,
            "token": token,
            "tool_calls": [],
            "iteration": 0,
            "should_continue": True,
            "final_answer": None,
            "error": None,
            "thoughts": []
        }
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        initial_state["messages"].append({"role": "user", "content": user_input})
        
        # æµå¼è¿è¡Œ
        last_thoughts_count = 0
        async for event in self.app.astream(initial_state):
            for node_name, node_output in event.items():
                # å‘é€æ€è€ƒè¿‡ç¨‹ï¼ˆåªå‘é€æ–°å¢çš„ï¼‰
                thoughts = node_output.get("thoughts", [])
                if len(thoughts) > last_thoughts_count:
                    for thought in thoughts[last_thoughts_count:]:
                        yield StreamEvent(event="thinking", data=thought)
                    last_thoughts_count = len(thoughts)
                
                # å‘é€å·¥å…·è°ƒç”¨ä¿¡æ¯
                if node_output.get("tool_calls"):
                    for tc in node_output["tool_calls"]:
                        yield StreamEvent(
                            event="tool_call",
                            data={
                                "name": tc.name,
                                "arguments": tc.arguments
                            }
                        )
                
                # å‘é€å·¥å…·æ‰§è¡Œç»“æœï¼ˆç”¨äºå‰ç«¯ç‰¹æ®Šæ¸²æŸ“ï¼‰
                messages = node_output.get("messages", [])
                for msg in messages:
                    if msg.get("role") == "tool":
                        try:
                            tool_data = json.loads(msg.get("content", "{}"))
                            # æ£€æµ‹æ˜¯å¦æ˜¯è®ºæ–‡æœç´¢ç»“æœ
                            if tool_data.get("results") and isinstance(tool_data["results"], list):
                                if tool_data["results"] and "title" in tool_data["results"][0]:
                                    yield StreamEvent(
                                        event="papers",
                                        data={
                                            "query": tool_data.get("query", ""),
                                            "total": tool_data.get("total_count", len(tool_data["results"])),
                                            "papers": tool_data["results"]
                                        }
                                    )
                        except:
                            pass
                
                # å‘é€æœ€ç»ˆç­”æ¡ˆ
                if node_output.get("final_answer"):
                    yield StreamEvent(
                        event="answer",
                        data=node_output["final_answer"]
                    )
        
        yield StreamEvent(event="done", data=None)


# å…¨å±€ Agent å®ä¾‹
_agent_instance: Optional[ResearchAgent] = None


def get_agent() -> ResearchAgent:
    """è·å– Agent å•ä¾‹"""
    global _agent_instance
    if _agent_instance is None:
        _agent_instance = ResearchAgent()
    return _agent_instance

