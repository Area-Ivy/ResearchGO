# ResearchGO

AI-powered research assistant with intelligent chat, literature search, and analytics dashboard.

## Features

- ğŸ¤– **AI Chat Assistant**: Real-time streaming responses powered by OpenAI GPT-4o
- ğŸ§® **Math Formula Rendering**: LaTeX/KaTeX support for mathematical expressions
- ğŸ“š **Literature Search**: Search 250M+ academic papers from OpenAlex
- ğŸ” **Smart Filtering**: Filter by year, citations, open access, and more
- ğŸ§  **Vector Search**: Semantic search powered by Milvus vector database
- ğŸ¯ **Similarity Detection**: Find similar papers based on content meaning
- ğŸ“ **AI Summarization**: Generate structured summaries of research papers
- ğŸ“„ **Citation Export**: Export in BibTeX, RIS, APA, and MLA formats
- ğŸ”— **Chat Integration**: Discuss papers directly with AI assistant
- ğŸ“Š **Research Dashboard**: Track your research activity and progress
- ğŸ¨ **Modern UI**: Deep tech aesthetic with glassmorphism and neon effects
- ğŸ”„ **Real-time Updates**: Server-Sent Events (SSE) for streaming responses
- ğŸ’¾ **Smart Caching**: Keep-alive component caching to prevent unnecessary re-renders

## Tech Stack

### Frontend
- Vue 3 (Composition API)
- Vite
- Chart.js for visualizations
- Marked for Markdown rendering
- KaTeX for LaTeX math formula rendering
- Highlight.js for code syntax highlighting

### Backend
- FastAPI
- OpenAI API (GPT-4o)
- OpenAlex API (academic search)
- SSE (Server-Sent Events)
- Python 3.9+

### Infrastructure
- **Milvus 2.3.3** - å‘é‡æ•°æ®åº“ï¼Œç”¨äºè¯­ä¹‰æœç´¢
- **Attu** - Milvus å¯è§†åŒ–ç®¡ç†ç•Œé¢
- **MinIO** - å¯¹è±¡å­˜å‚¨æœåŠ¡
- **etcd** - åˆ†å¸ƒå¼é…ç½®å­˜å‚¨

## Quick Start

### Prerequisites
- Node.js 16+
- Python 3.9+
- OpenAI API key

### Backend Setup

1. **Navigate to backend:**
   ```bash
   cd backend
   ```

2. **Create virtual environment:**
   ```bash
   python -m venv venv
   
   # Windows
   .venv\Scripts\activate
   
   # Linux/Mac
   source venv/bin/activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Create `.env` file:**
   ```bash
   # backend/.env
   OPENAI_API_KEY=your_openai_api_key_here
   OPENAI_MODEL=gpt-4o
   CONTACT_EMAIL=your_email@example.com  # Optional, for OpenAlex
   HOST=0.0.0.0
   PORT=8000
   ALLOWED_ORIGINS=http://localhost:5173
   ```

5. **Run backend:**
   ```bash
   python run.py
   ```

   Backend will be available at: `http://localhost:8000`

### Frontend Setup

1. **Navigate to frontend:**
   ```bash
   cd frontend
   ```

2. **Install dependencies:**
   ```bash
   npm install
   ```

3. **Create `.env` file:**
   ```bash
   # frontend/.env
   VITE_API_BASE_URL=http://localhost:8000
   ```

4. **Run frontend:**
   ```bash
   npm run dev
   ```

   Frontend will be available at: `http://localhost:5173`

### Milvus å‘é‡æ•°æ®åº“è®¾ç½®

1. **å¯åŠ¨ Milvus å’Œç›¸å…³æœåŠ¡ï¼š**
   ```bash
   docker-compose up -d
   ```

2. **éªŒè¯æœåŠ¡çŠ¶æ€ï¼š**
   ```bash
   docker-compose ps
   ```
   
   ç¡®ä¿ä»¥ä¸‹æœåŠ¡éƒ½åœ¨è¿è¡Œï¼š
   - âœ… Milvus (ç«¯å£ 19530, 9091)
   - âœ… Attu (ç«¯å£ 9002) - å¯è§†åŒ–ç®¡ç†ç•Œé¢
   - âœ… etcd (å¥åº·çŠ¶æ€)
   - âœ… MinIO (ç«¯å£ 9000, 9001)

3. **è®¿é—® Attu ç®¡ç†ç•Œé¢ï¼š**
   - æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼š`http://localhost:9002`
   - è¿æ¥åœ°å€è¾“å…¥ï¼š`localhost:19530`
   - ç‚¹å‡» "Connect" è¿æ¥

4. **ä½¿ç”¨ Python è¿æ¥ï¼š**
   ```python
   from app.services.milvus_service import milvus_service
   
   # è¿æ¥åˆ° Milvus
   milvus_service.connect()
   
   # åˆ›å»ºé›†åˆ
   milvus_service.create_collection(dim=768)
   
   # åˆ›å»ºç´¢å¼•
   milvus_service.create_index()
   ```

5. **è¯¦ç»†ä½¿ç”¨æŒ‡å—ï¼š**
   - ğŸ“– [Milvus ä½¿ç”¨æŒ‡å—](docs/MILVUS_USAGE.md) - å®Œæ•´çš„ä½¿ç”¨æ•™ç¨‹
   - ğŸ“– [Milvus éƒ¨ç½²æ–‡æ¡£](docs/MILVUS_SETUP.md) - éƒ¨ç½²å’Œé…ç½®è¯´æ˜
   - ğŸ“– [å¿«é€Ÿå¼€å§‹](docs/QUICK_START.md) - å¿«é€Ÿå…¥é—¨æŒ‡å—

## Usage

### Dashboard
Visit `http://localhost:5173/` to see:
- Photon usage statistics
- Knowledge entropy visualization
- Daily research recommendations
- Field progress updates
- Cognitive architecture radar chart
- Neural imprint trends
- Background synthesis queue

### Milvus Manager
Visit `http://localhost:5173/milvus` to:
- View all vector collections
- Create and delete collections  
- Load/Release collections from memory
- Monitor collection statistics
- View collection details and schemas

### Chat Assistant
Visit `http://localhost:5173/chat` to:
- Ask questions about research topics
- Get explanations of complex concepts
- Discuss papers and methodologies
- Receive formatted responses with code highlighting

### Literature Search
Visit `http://localhost:5173/literature` to:
- Search 250M+ academic papers from OpenAlex
- Filter by year, citations, open access status
- View detailed paper information and abstracts
- Generate AI-powered summaries in Chinese or English
- Export citations in BibTeX, RIS, APA, or MLA format
- Discover related papers
- Discuss papers directly with AI assistant

## Project Structure

```
ResearchGO/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ views/
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.vue              # Dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat.vue              # Chat interface
â”‚   â”‚   â”‚   â””â”€â”€ LiteratureSearch.vue  # Literature search
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ literature.js         # Literature API client
â”‚   â”‚   â”œâ”€â”€ router/
â”‚   â”‚   â”‚   â””â”€â”€ index.js              # Routes
â”‚   â”‚   â”œâ”€â”€ config.js                 # API configuration
â”‚   â”‚   â”œâ”€â”€ style.css                 # Global styles
â”‚   â”‚   â””â”€â”€ App.vue                   # Main layout
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py               # Chat endpoints
â”‚   â”‚   â”‚   â””â”€â”€ literature.py         # Literature endpoints
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ openai_service.py     # OpenAI integration
â”‚   â”‚   â”‚   â””â”€â”€ openalex_service.py   # OpenAlex integration
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py               # Chat models
â”‚   â”‚   â”‚   â””â”€â”€ literature.py         # Literature models
â”‚   â”‚   â””â”€â”€ main.py               # FastAPI app
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ run.py
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ README.md                      # This file
```

## API Documentation

Once the backend is running, visit:
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

## Environment Variables

### Backend (.env)
```env
OPENAI_API_KEY=sk-...           # Required: Your OpenAI API key
OPENAI_MODEL=gpt-4o             # Optional: Model to use
HOST=0.0.0.0                     # Optional: Server host
PORT=8000                        # Optional: Server port
ALLOWED_ORIGINS=http://localhost:5173 # Optional: CORS origins
```

### Frontend (.env)
```env
VITE_API_BASE_URL=http://localhost:8000 # Backend API URL
```

## Development

### Frontend Development
```bash
cd frontend
npm run dev      # Start dev server
npm run build    # Build for production
npm run preview  # Preview production build
```

### Backend Development
```bash
cd backend
python run.py    # Start with auto-reload
```

## Troubleshooting

### Chat not working
1. Ensure backend is running: `http://localhost:8000/health`
2. Check OpenAI API key is set in `backend/.env`
3. Verify CORS origins include your frontend URL
4. Check browser console for errors

### Connection errors
1. Verify backend is running on port 8000
2. Check `VITE_API_BASE_URL` in frontend `.env`
3. Ensure no firewall blocking connections

### OpenAI API errors
1. Verify API key is valid
2. Check you have sufficient credits
3. Ensure model name is correct

## License

MIT

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

